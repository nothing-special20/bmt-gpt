{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import traceback\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "%env OPEN_AI_KEY=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\n",
    "%env RAPID_API_KEY=bff2c4170amsh85404744e9ae8c1p152048jsn9317c672be9c\n",
    "%env HUGGINGFACEHUB_API_TOKEN=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\n",
    "\n",
    "OPEN_AI_KEY = os.getenv('OPEN_AI_KEY', default='')\n",
    "os.environ['OPENAI_API_KEY'] = OPEN_AI_KEY\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN', default='')\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open AI Functions\n",
    "openai.api_key = OPEN_AI_KEY\n",
    "\n",
    "def open_ai_summarize_text(prompt, max_tokens):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        n = 1,\n",
    "        stop=None,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def gpt_analyze_reviews(agg_reviews, asin, partial_prompt):\n",
    "    asin = ';'.join(asin)\n",
    "    prompt = '{}{}'.format(partial_prompt, agg_reviews)\n",
    "    print(prompt)\n",
    "    x = open_ai_summarize_text(prompt, max_tokens=3500)\n",
    "\n",
    "    x = json.loads(json.dumps(x))\n",
    "\n",
    "    results = str(x['choices'][0]['message']['content'])\n",
    "    results = re.sub('\\n', '', results)\n",
    "    completion_tokens = str(x['usage']['completion_tokens'])\n",
    "    prompt_tokens = str(x['usage']['prompt_tokens'])\n",
    "\n",
    "    output = {\n",
    "            \"asin\": asin,\n",
    "            \"prompt\": partial_prompt,\n",
    "            \"gpt_evaluation\": results,\n",
    "            \"completion_tokens\": completion_tokens,\n",
    "            \"prompt_tokens\": prompt_tokens,\n",
    "        }\n",
    "\n",
    "    print('gpt analysis done')\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbde65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rapid API Functions\n",
    "def _get_reviews(asin, pg_num):\n",
    "    url = \"https://amazon23.p.rapidapi.com/reviews\"\n",
    "    \n",
    "    querystring = {\n",
    "        \"asin\": asin,\n",
    "        \"sort_by\": \"recent\",\n",
    "        \"country\":\"US\", \n",
    "        \"page\": pg_num}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": os.getenv('RAPID_API_KEY', default=''),\n",
    "        \"X-RapidAPI-Host\": \"amazon23.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "def get_reviews(asin, pg_num):\n",
    "    counter = 0\n",
    "    while counter < 5:\n",
    "        _response = _get_reviews(asin, pg_num)\n",
    "        response = json.loads(_response)\n",
    "        if 'errors' in response.keys():\n",
    "            print('temp failure')\n",
    "            time.sleep(5)\n",
    "            response = json.loads(\"{}\")\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if counter == 5:\n",
    "        print('total failure')\n",
    "\n",
    "    print('succcess')\n",
    "    return response\n",
    "\n",
    "def process_reviews(user, reviews):\n",
    "    output = []\n",
    "    try:\n",
    "        for rev in reviews['result']:\n",
    "            json_data = {\n",
    "                \"USER\": user,\n",
    "                \"REVIEW_ID\": rev['id'],\n",
    "                \"ASIN_ORIGINAL_ID\": rev['asin']['original'],\n",
    "                \"ASIN_VARIANT_ID\": rev['asin']['variant'],\n",
    "                \"REVIEWER_NAME\": rev['name'],\n",
    "                \"RATING\": rev['rating'],\n",
    "                \"REVIEW_DATE\": rev['date']['date'],\n",
    "                \"REVIEW_DATE_UNIX\": rev['date']['unix'],\n",
    "                \"TITLE\": rev['title'],\n",
    "                \"REVIEW\": rev['review'],\n",
    "                \"VERIFIED_PURCHASE\": rev['verified_purchase'],\n",
    "                \"LOAD_DATE\": datetime.now(),\n",
    "            }\n",
    "\n",
    "            # Convert the dict to a JSON string with custom encoding\n",
    "            output.append(json_data)\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_keyword_details(keyword):\n",
    "    url = 'https://amazon23.p.rapidapi.com/product-search'\n",
    "\n",
    "    querystring = {\n",
    "        \"query\": keyword, \n",
    "        \"country\": \"US\"\n",
    "        }\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": os.getenv('RAPID_API_KEY', default=''),\n",
    "        \"X-RapidAPI-Host\": \"amazon23.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20877ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maual_asins = ['B07ZNPTKQ6', 'B08MWQYWGG', 'B077QV8VQ6', 'B07L38V2X1', 'B01A9H65HU', 'B082X35Z16', 'B06Y5RVQ2C', 'B00PCEH6S8', 'B07BPCZNLD', 'B0817MZZGT', 'B000LH6ODE', 'B0878M41V7', 'B093GR46CS', 'B001FX9FV6', 'B00MX2BP2U', 'B07J4LPML4']\n",
    "top_boxing_gloves = get_keyword_details('boxing gloves')\n",
    "top_boxing_gloves_asins = [x['asin'] for x in bg['result']]\n",
    "asins = list(set([*maual_asins, *top_boxing_gloves_asins]))\n",
    "asin_pg_pairs = []\n",
    "\n",
    "print('Unique ASINs to fetch:\\t' + str(len(top_boxing_gloves_asins)))\n",
    "\n",
    "for asin in asins:\n",
    "    for pg_num in range(1, 50):\n",
    "        temp = {\n",
    "            'asin': asin,\n",
    "            'pg_num': pg_num\n",
    "        }\n",
    "        asin_pg_pairs.append(temp)\n",
    "        \n",
    "raw_reviews = []\n",
    "# asin = 'B07ZNPTKQ6'\n",
    "raw_reviews = []\n",
    "\n",
    "print('Pages of ASIN data to fetch:\\t' + str(len(asin_pg_pairs)))\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for x in asin_pg_pairs:\n",
    "    counter += 1\n",
    "    print(str(counter) + ' of ' + str(len(asin_pg_pairs)))\n",
    "    temp = get_reviews(x['asin'], x['pg_num']) \n",
    "    if temp == {}:\n",
    "        break\n",
    "    else:\n",
    "        raw_reviews.append(temp)\n",
    "        \n",
    "    if counter % 10 == 0:\n",
    "        proc_reviews = []\n",
    "        for x in raw_reviews:\n",
    "            proc_reviews.extend(process_reviews('user', x))\n",
    "            \n",
    "        proc_reviews_df = pd.concat([pd.DataFrame([x]) for x in proc_reviews])\n",
    "        proc_reviews_df.to_csv('boxing_glove_reviews.csv', sep='|', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# reviews = [x['REVIEW'] for x in proc_reviews]\n",
    "proc_reviews_df = pd.concat([pd.DataFrame([x]) for x in proc_reviews])\n",
    "proc_reviews_df.to_csv('boxing_glove_reviews.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63139502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Langchain Functions\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "\n",
    "template = \"Read the following review and return ONLY a JSON object composed of the following, with keys noted in single quotes (note, if the question cannot be answered, answer 'NA'): 1) 'who': the people mentioned in the review, separated by a comma. Please ignore pronouns. 2) 'when': Any dates mentioned 3) 'where': Where they use it 4) 'description': A brief description of how they feel about the product. 5) 'how_often' How often the use it. 6) 'motivation': why they bought it. 7) 'expectations': what the reviewer expects from the product. The reviews: {review}.\"\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Review: {review}\n",
    "Extracted_Data: {extracted_data}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"review\", \"extracted_data\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "####\n",
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\n",
    "        \"review\": \"These are a great fit for our 16-year-old boxer who is lean and tall. I’ve only heard him complain that they hurt his wrist a little bit so he bought some straps to wrap his wrist and hands with. That may be a normal thing with boxing gloves. He’s tearing the punching bag up and having a great time. He really likes these.\", \n",
    "        \"extracted_data\": \"\"\"{\n",
    "            \"who\": \"16-year-old boxer who is lean and tall\",\n",
    "            \"when\": \"N/A\",\n",
    "            \"where\": \"N/A\",\n",
    "            \"how_often\": \"N/A\",\n",
    "            \"description\": \"He’s tearing the punching bag up and having a great time. He really likes these.\",\n",
    "            \"motivation\": \"I’ve only heard him complain that they hurt his wrist a little bit so he bought some straps to wrap his wrist and hands with\",\n",
    "            \"expectations\": \"N/A\"\n",
    "        }\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"review\": \"These are comfortable, and nicely padded for heavy bag use.I paired them with gel wraps and have no issues with long bag work sessions!\", \n",
    "        \"extracted_data\": \"\"\"{\n",
    "            \"who\": \"16-year-old boxer who is lean and tall\",\n",
    "            \"when\": \"heavy bag use\",\n",
    "            \"where\": \"N/A\",\n",
    "            \"how_often\": \"N/A\",\n",
    "            \"description\": \"comfortable, and nicely padded\",\n",
    "            \"motivation\": \"N/A\",\n",
    "            \"expectations\": \"N/A\"\n",
    "        }\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "examples = []\n",
    "\n",
    "\n",
    "# # Finally, we create the `FewShotPromptTemplate` object.\n",
    "# few_shot_prompt = FewShotPromptTemplate(\n",
    "#     # These are the examples we want to insert into the prompt.\n",
    "#     examples=examples,\n",
    "#     # This is how we want to format the examples when we insert them into the prompt.\n",
    "# #     example_prompt=example_prompt,\n",
    "#     # The prefix is some text that goes before the examples in the prompt.\n",
    "#     # Usually, this consists of intructions.\n",
    "#     prefix=prefix,\n",
    "#     # The suffix is some text that goes after the examples in the prompt.\n",
    "#     # Usually, this is where the user input will go\n",
    "#     suffix=\"Review: {input}\\Extracted_Data: \",\n",
    "#     # The input variables are the variables that the overall prompt expects.\n",
    "#     input_variables=[\"input\"],\n",
    "#     # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "# #     example_separator=\"\\n\",\n",
    "# )\n",
    "\n",
    "simple_prompt = PromptTemplate(input_variables=[\"review\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edfa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d15aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_review = reviews[26]\n",
    "review_details = chain.run(x_review)\n",
    "print(review_details)\n",
    "print(reviews[26])\n",
    "# lol = chain.run('roar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f288ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial_prompt = \"Read the following reviews (each distinct review will be enclosed by <revTag> and </revTag>) and return ONLY a combined list [] of JSON object for each review composed of the following, with keys noted in single quotes (note, if the question cannot be answered, answer 'NA', and please do not list '...' as an answer): 1) 'who': the people mentioned in the review, separated by a comma. 2) 'when': Any dates mentioned 3) 'where': Where they use it 4) 'description': A brief description of how they feel about the product. 5) 'how_often' How often the use it. 6) 'motivation': why they bought it. 7) 'expectations': what the reviewer expects from the product. The reviews: \"partial_prompt = \"Read the following reviews (each distinct review will be enclosed by <revTag> and </revTag>) and return ONLY a combined list [] of JSON object for each review composed of the following, with keys noted in single quotes (note, if the question cannot be answered, answer 'NA', and please do not list '...' as an answer): 1) 'who': the people mentioned in the review, separated by a comma. 2) 'when': Any dates mentioned 3) 'where': Where they use it 4) 'description': A brief description of how they feel about the product. 5) 'how_often' How often the use it. 6) 'motivation': why they bought it. 7) 'expectations': what the reviewer expects from the product. The reviews: \"\n",
    "\n",
    "# for x in reviews:\n",
    "#     print('~~~', x)\n",
    "reviews[5]\n",
    "# agg_reviews = ' '.join(['<revTag>' + x + '</revTag>' for x in reviews])\n",
    "# gpt_analyze_reviews(agg_reviews, asin, partial_prompt)\n",
    "# gpt_result = gpt_analyze_reviews(agg_reviews, '', partial_prompt\n",
    "# gpt_query_result = json.loads(re.sub(\"'\", '\"', gpt_result['gpt_evaluation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ad51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for x in reviews:\n",
    "    print('~~~', str(counter), '\\t', x)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5bb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_boxing_gloves = get_keyword_details('boxing gloves')\n",
    "top_boxing_gloves_asins = [x['asin'] for x in bg['result']]\n",
    "review_count = [int(x['reviews']['total_reviews']) for x in bg['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(bg['result'], indent=4))\n",
    "\n",
    "\n",
    "# len(top_asins)\n",
    "\n",
    "lol = [*top_boxing_gloves_asins, *top_boxing_gloves_asins]\n",
    "# print(sum(review_count))\n",
    "print(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "5 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b34039",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Spacy Functions\n",
    "from collections import Counter\n",
    "import spacy\n",
    "# import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# 'NOUN', 'ADJ'\n",
    "def find_types_of_words(text, word_type_list, nlp=nlp):\n",
    "    doc = nlp(text)\n",
    "    words = [x.text.lower() for x in doc if x.pos_ in word_type_list]\n",
    "    words = list(set(words))\n",
    "    words.sort()\n",
    "    ignore_words = ['have']\n",
    "    words = [x for x in words if x not in ignore_words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "def most_common_words(text_list, word_type_list):\n",
    "    all_review_adjectives = []\n",
    "    for review in text_list:\n",
    "        adjs = find_types_of_words(review, word_type_list)\n",
    "        all_review_adjectives.extend(adjs)\n",
    "    most_common_words = Counter(all_review_adjectives).most_common(20)\n",
    "    return most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c63ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('boxing_glove_reviews.csv', sep='|')\n",
    "titles = reviews_df['TITLE'].astype(str).to_list()\n",
    "reviews = reviews_df['REVIEW'].astype(str).to_list()\n",
    "# top_nouns = most_common_words(titles, 'NOUN')\n",
    "# top_adjectives = most_common_words(titles, 'ADJ')\n",
    "# top_verbs = most_common_words(titles, 'VERB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef405ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "title_top_nouns_adjs_verbs = most_common_words(titles, ['NOUN', 'ADJ', 'VERB'])\n",
    "print('title_top_nouns_adjs_verbs', str(start_time - datetime.now()))\n",
    "review_top_nouns_adjs_verbs = most_common_words(reviews, ['NOUN', 'ADJ', 'VERB'])\n",
    "print('review_top_nouns_adjs_verbs', str(start_time - datetime.now()))\n",
    "review_top_nouns_adjs_verbs_vals = [x[0] for x in review_top_nouns_adjs_verbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_top_nouns_adjs_verbs = most_common_words(reviews, ['PREP'])\n",
    "review_top_nouns_adjs_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_top_nouns_adjs_verbs_regex = '(?:' + '|'.join(review_top_nouns_adjs_verbs_vals) + ')'\n",
    "review_top_nouns_adjs_verbs_regex = '[ 0-9a-zA-Z]{1,55} ' + review_top_nouns_adjs_verbs_regex + '[ 0-9a-zA-Z]{1,55}[ \\\\.]{1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a031a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in reviews[0:10]:\n",
    "    print('~~~~~~~~', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b82f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_around_top_words(review):\n",
    "    try:\n",
    "        return re.findall(review_top_nouns_adjs_verbs_regex, review)\n",
    "    except:\n",
    "        return ['']\n",
    "\n",
    "# [phrase_around_top_words(x) for x in reviews[0:10]]\n",
    "\n",
    "def phrases_for_classification(reviews):\n",
    "    raw_phrases_around_core_words = []\n",
    "    for x in reviews:\n",
    "        temp = phrase_around_top_words(x)\n",
    "        raw_phrases_around_core_words.extend(temp)\n",
    "\n",
    "    counter = 0\n",
    "    _reviews_for_gpt_prompt = []\n",
    "    for x in raw_phrases_around_core_words:\n",
    "        counter += 1\n",
    "        _reviews_for_gpt_prompt.append(str(counter) + ' ' + x + '\\n')\n",
    "    #     print(str(counter), x)\n",
    "\n",
    "    return ' '.join(_reviews_for_gpt_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91adb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "template = \"\"\"\n",
    "    Question: Please create 10 categories for the reviews below: {reviews}\n",
    "    \n",
    "    Answer: Here are 10 categories:\n",
    "\"\"\" #+ reviews_for_gpt_prompta\n",
    "openai_llm = OpenAI(verbose=True, temperature=.1, model_name=\"text-davinci-003\")\n",
    "simple_prompt = PromptTemplate(input_variables=[\"reviews\"], template=template)\n",
    "# openai_llm = ChatOpenAI(verbose=True, temperature=.1, model_name=\"gpt-3.5-turbo\")\n",
    "chain = LLMChain(llm=openai_llm, prompt=simple_prompt)\n",
    "test_data = phrases_for_classification(reviews[0:25])\n",
    "categories = chain.run(test_data)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae899b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = [chain.run(phrases_for_classification(reviews[0:25])),\n",
    "#                    chain.run(phrases_for_classification(reviews[25:50])),\n",
    "#                    chain.run(phrases_for_classification(reviews[50:75])),\n",
    "#                    chain.run(phrases_for_classification(reviews[75:100])),\n",
    "#                    chain.run(phrases_for_classification(reviews[100:125])),\n",
    "#                    chain.run(phrases_for_classification(reviews[125:150])),\n",
    "#                    chain.run(phrases_for_classification(reviews[175:200])),\n",
    "#                    chain.run(phrases_for_classification(reviews[200:225])),\n",
    "#                    chain.run(phrases_for_classification(reviews[225:250])),\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = []\n",
    "\n",
    "for x in range(0,5):\n",
    "    temp_data = phrases_for_classification(reviews[0:25])\n",
    "    temp_categories = chain.run(temp_data)\n",
    "    temp_categories = temp_categories.split('\\n')\n",
    "    print(temp_categories)\n",
    "    categories_list.extend(temp_categories)\n",
    "    \n",
    "print('~~~~')\n",
    "\n",
    "categories_list = [re.sub('[0-9]{1,4}. ', '', x) for x in categories_list]\n",
    "\n",
    "for x in categories_list:\n",
    "    print(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in list(set([x.strip() for x in categories_list])):\n",
    "    print('~',y,'~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "test_data = phrases_for_classification(reviews[0:25])\n",
    "test = chain.run(test_data)\n",
    "print('Total time to process: ', str(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b268abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hugging face\n",
    "# from langchain import HuggingFaceHub\n",
    "# repo_id = \"bert-base-uncased\" # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
    "# llm = HuggingFaceHub(repo_id=repo_id) #, model_kwargs={\"temperature\":0, \"max_length\":64}\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "# classifier = pipeline(\"zero-shot-classification\", model='bert-base-uncased')\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b87917",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca492ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizer(raw_phrases_around_core_words[30])\n",
    "print(raw_phrases_around_core_words[30])\n",
    "summarizer(raw_phrases_around_core_words[30], max_length=5, min_length=1, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_phrases_around_core_words\n",
    "labels = ['Fit and Size', 'Comfort', 'Quality and Durability', 'Design and Appearance', 'Performance and Functionality', 'Support', 'Ease of Use', \"Beginner's Experience\", 'User Experience Over Time']\n",
    "classifier(raw_phrases_around_core_words[30], candidate_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bce23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review_phrase in raw_phrases_around_core_words:\n",
    "    start_time = datetime.now()\n",
    "    x = classifier(review_phrase, candidate_labels=labels)\n",
    "    print('~~~~~~~')\n",
    "    print(review_phrase)\n",
    "    print(x['labels'][0])\n",
    "    print('Time to complete:\\t', str(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2123f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.now()\n",
    "[classifier(rev, candidate_labels=labels)['labels'][0] for rev in reviews_df['REVIEW'].to_list()[0:20]]\n",
    "\n",
    "print('Total time to finish:\\t', str(datetime.now() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def split_list_into_sublists(list_to_split, number_of_sublists):\n",
    "    length_of_sublist = len(list_to_split) // number_of_sublists\n",
    "    return [list_to_split[i:i+length_of_sublist] for i in range(0, len(list_to_split), length_of_sublist)]\n",
    "\n",
    "def top_label(reviews):\n",
    "    all_labels = []\n",
    "    for rev in reviews:\n",
    "        temp = classifier(rev, candidate_labels=labels)['labels'][0]\n",
    "        all_labels.append(temp)\n",
    "        \n",
    "    return all_labels\n",
    "\n",
    "reviews = reviews_df['REVIEW'].to_list()[0:4]\n",
    "reviews_sublists = split_list_into_sublists(reviews, 4)\n",
    "\n",
    "print(reviews_sublists)\n",
    "\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "assigned_labels = pool.map(top_label, zip(reviews_sublists))\n",
    "# pool.map(top_label, reviews_sublists)\n",
    "\n",
    "assigned_labels\n",
    "\n",
    "# reviews_sublists\n",
    "# reviews_sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbc3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'What does the reviewer think about this product? ',\n",
    "    'context': 'Very comfortable for my son . Right fit .'\n",
    "}\n",
    "res = nlp(QA_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d06ce4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_top_nouns_adjs_verbs\n",
    "# sum([x[1] for x in review_top_nouns_adjs_verbs])\n",
    "review_top_nouns_adjs_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_top_nouns_adjs_verbs\n",
    "# sum([x[1] for x in title_top_nouns_adjs_verbs])\n",
    "title_top_nouns_adjs_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdcdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "\n",
    "starttime = datetime.now()\n",
    "for x in reviews_df['REVIEW'].tolist()[0:15]:\n",
    "    QA_input = {\n",
    "        'question': 'What topic what you categorize this review as?',\n",
    "        'context': x\n",
    "    }\n",
    "    res = nlp(QA_input)\n",
    "    \n",
    "    print('~~~~~')\n",
    "    print(x)\n",
    "    print('~')\n",
    "    print(res['answer'])\n",
    "    \n",
    "print('Total time:\\t' + str(datetime.now() - starttime ))\n",
    "title_top_nouns_adjs_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35992e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Create a blank English nlp object\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "# config = {\"mode\": \"rule\"}\n",
    "# spacy_nlp.add_pipe(\"lemmatizer\", config=config)\n",
    "\n",
    "def remove_stops(doc):\n",
    "    # Filter out stop words by using the `token.is_stop` attribute\n",
    "    return [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "def lemmatize(doc):\n",
    "    # Take the `token.lemma_` of each non-stop word\n",
    "    return [token.lemma_ for token in doc if not token.is_stop]\n",
    "\n",
    "# doc = nlp(\"Hello world!\")\n",
    "sample_reviews = reviews_df['REVIEW'].tolist()[0:5000]\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "sample_reviews = [re.sub(r'[^\\w\\s]', '', str(x)) for x in sample_reviews]\n",
    "# sample_reviews = [spacy_nlp(str(x)) for x in sample_reviews]\n",
    "\n",
    "# sample_reviews = [remove_stops(x) for x in sample_reviews]\n",
    "# sample_reviews = [' '.join(x) for x in sample_reviews]\n",
    "sample_reviews = [lemmatize(spacy_nlp(x)) for x in sample_reviews]\n",
    "sample_reviews = [' '.join(x) for x in sample_reviews]\n",
    "\n",
    "print('Total time:\\t' + str(datetime.now() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_input = {\n",
    "    'question': 'Which of these words refers to a person or people?',\n",
    "    'context': 'My son loves these.'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e706255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "topic_model = BERTopic(min_topic_size=10)\n",
    "topics, probs = topic_model.fit_transform(sample_reviews)\n",
    "print('Total time:\\t' + str(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()#['Name']\n",
    "# topic_model.get_topic(-1)\n",
    "# sample_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e302cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_term_rank()\n",
    "# reviews_to_predict = reviews_df['REVIEW'].tolist()[5001:10002]\n",
    "reviews_to_predict = reviews_df['REVIEW'].tolist()[5001:5005]\n",
    "reviews_to_predict = [str(x) for x in reviews_to_predict]\n",
    "reviews_to_predict = [lemmatize(spacy_nlp(x)) for x in reviews_to_predict]\n",
    "reviews_to_predict = [' '.join(x) for x in reviews_to_predict]\n",
    "topic_model.transform(reviews_to_predict)\n",
    "# topic_model.get_document_info(reviews_to_predict)\n",
    "# topic_model.get_document_info(sample_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a314f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topic(rev):\n",
    "    rev = str(rev)\n",
    "    rev = lemmatize(spacy_nlp(rev))\n",
    "    rev = ' '.join(rev)\n",
    "    return topic_model.transform(rev)\n",
    "\n",
    "# review_df['TOPIC'] = review_df['REVIEW'].apply(lambda x: assign_topic(x))\n",
    "\n",
    "starttime = datetime.now()\n",
    "\n",
    "all_reviews = reviews_df['REVIEW'].tolist()\n",
    "all_reviews = [str(x) for x in all_reviews]\n",
    "all_reviews = [lemmatize(spacy_nlp(x)) for x in all_reviews]\n",
    "all_reviews = [' '.join(x) for x in all_reviews]\n",
    "print('Partial time:\\t', str(datetime.now() - starttime))\n",
    "reviews_df['TOPIC'] = topic_model.transform(all_reviews)[0]\n",
    "print('Total time:\\t', str(datetime.now() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df#['TOPIC'].to_list()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df[reviews_df['TOPIC']==-1]['REVIEW'].to_list()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(x) for x in sample_reviews][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sample_reviews[0:20]:\n",
    "    print('~~')\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672c4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmt-doc-processing",
   "language": "python",
   "name": "bmt-doc-processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
